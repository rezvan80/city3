{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rezvan80/city3/blob/main/Untitled48.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!apt-get update -y\n",
        "!apt-get install python3.7 python3.7-dev python3.7-distutils"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "334XWhQ-F5vx",
        "outputId": "bdd00939-451d-4cf4-e876-2835acd928a0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r0% [Working]\r            \rHit:1 http://security.ubuntu.com/ubuntu jammy-security InRelease\n",
            "\r0% [Connecting to archive.ubuntu.com (185.125.190.82)] [Connected to cloud.r-project.org (18.160.213\r                                                                                                    \rHit:2 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease\n",
            "\r0% [Connecting to archive.ubuntu.com (185.125.190.82)] [Connected to r2u.stat.illinois.edu (192.17.1\r                                                                                                    \rHit:3 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease\n",
            "\r0% [Connecting to archive.ubuntu.com (185.125.190.82)] [Connected to r2u.stat.illinois.edu (192.17.1\r                                                                                                    \rHit:4 https://r2u.stat.illinois.edu/ubuntu jammy InRelease\n",
            "Hit:5 http://archive.ubuntu.com/ubuntu jammy InRelease\n",
            "Hit:6 http://archive.ubuntu.com/ubuntu jammy-updates InRelease\n",
            "Hit:7 http://archive.ubuntu.com/ubuntu jammy-backports InRelease\n",
            "Hit:8 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease\n",
            "Hit:9 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy InRelease\n",
            "Hit:10 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease\n",
            "Reading package lists... Done\n",
            "W: Skipping acquire of configured file 'main/source/Sources' as repository 'https://r2u.stat.illinois.edu/ubuntu jammy InRelease' does not seem to provide it (sources.list entry misspelt?)\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "python3.7 is already the newest version (3.7.17-1+jammy1).\n",
            "python3.7-dev is already the newest version (3.7.17-1+jammy1).\n",
            "python3.7-distutils is already the newest version (3.7.17-1+jammy1).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 32 not upgraded.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!update-alternatives --install /usr/bin/python3 python3 /usr/bin/python3.7 1\n",
        "!update-alternatives --config python3"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5-sCm5z_JZMz",
        "outputId": "157ef5b4-cbd0-4d81-e34b-9c342dfb8b5a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "There are 3 choices for the alternative python3 (providing /usr/bin/python3).\n",
            "\n",
            "  Selection    Path                 Priority   Status\n",
            "------------------------------------------------------------\n",
            "  0            /usr/bin/python3.11   2         auto mode\n",
            "  1            /usr/bin/python3.10   1         manual mode\n",
            "  2            /usr/bin/python3.11   2         manual mode\n",
            "* 3            /usr/bin/python3.7    1         manual mode\n",
            "\n",
            "Press <enter> to keep the current choice[*], or type selection number: 3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python --version"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_uJvC1JeH_9S",
        "outputId": "98b329ce-240e-4bbd-f7ef-53643ccae8a3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Python 3.7.17\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!apt install python3-pip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KhVYJPjDG60k",
        "outputId": "b0882565-cdc7-4b15-f9bb-b0b3cfa89de8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "python3-pip is already the newest version (22.0.2+dfsg-1ubuntu0.5).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 32 not upgraded.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python --version"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "siDp4pmvG8ZM",
        "outputId": "21b4bcde-caf6-4105-e703-87d027a82344"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Python 3.7.17\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!rm -rf /content/CityFlow/build/\n",
        "!rm -rf /content/CityFlow/dist/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4HSNOETpDdnT",
        "outputId": "aac3cc3a-01ff-4ef7-faae-810fd0de00df"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "shell-init: error retrieving current directory: getcwd: cannot access parent directories: No such file or directory\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install cmake"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H8Mv3xIFKpJF",
        "outputId": "898d4773-f921-42e7-871d-fe7278e46b9f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting cmake\n",
            "  Using cached cmake-3.31.4-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (27.8 MB)\n",
            "Installing collected packages: cmake\n",
            "Successfully installed cmake-3.31.4\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!update-alternatives --install /usr/bin/python3 python3 /usr/bin/python3.7 1\n",
        "!update-alternatives --config python3"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TaWE9YylKwWj",
        "outputId": "1acae376-d3db-4f2b-a2b8-df76b1816f59"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "There are 3 choices for the alternative python3 (providing /usr/bin/python3).\n",
            "\n",
            "  Selection    Path                 Priority   Status\n",
            "------------------------------------------------------------\n",
            "  0            /usr/bin/python3.11   2         auto mode\n",
            "* 1            /usr/bin/python3.10   1         manual mode\n",
            "  2            /usr/bin/python3.11   2         manual mode\n",
            "  3            /usr/bin/python3.7    1         manual mode\n",
            "\n",
            "Press <enter> to keep the current choice[*], or type selection number: 1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cd /content/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w72o2a0Bu-IB",
        "outputId": "6823de52-dbad-4ee8-befc-a917ba4f9307"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/cityflow-project/CityFlow.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IgxS76Azur9G",
        "outputId": "5e06eb9e-612b-4beb-dc3e-4cf8f288af76"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'CityFlow' already exists and is not an empty directory.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cd /content/CityFlow/build"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AMi0v4SbuzyK",
        "outputId": "9797610c-dd76-4ce5-d24e-288be970eb10"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/CityFlow/build\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir build\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "FqJwkwhZDj0i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "!cmake ..\n",
        "!make"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pEMWCHXTvt4N",
        "outputId": "0bf02705-865c-4535-c068-c57e00a5db93"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[0mCMake Deprecation Warning at CMakeLists.txt:1 (cmake_minimum_required):\n",
            "  Compatibility with CMake < 3.10 will be removed from a future version of\n",
            "  CMake.\n",
            "\n",
            "  Update the VERSION argument <min> value.  Or, use the <min>...<max> syntax\n",
            "  to tell CMake that the project requires at least <min> but has been updated\n",
            "  to work with policies introduced by <max> or earlier.\n",
            "\n",
            "\u001b[0m\n",
            "-- The C compiler identification is GNU 11.4.0\n",
            "-- The CXX compiler identification is GNU 11.4.0\n",
            "-- Detecting C compiler ABI info\n",
            "-- Detecting C compiler ABI info - done\n",
            "-- Check for working C compiler: /usr/bin/cc - skipped\n",
            "-- Detecting C compile features\n",
            "-- Detecting C compile features - done\n",
            "-- Detecting CXX compiler ABI info\n",
            "-- Detecting CXX compiler ABI info - done\n",
            "-- Check for working CXX compiler: /usr/bin/c++ - skipped\n",
            "-- Detecting CXX compile features\n",
            "-- Detecting CXX compile features - done\n",
            "-- Found Submodule: extern/pybind11/CMakeLists.txt\n",
            "-- Found Submodule: extern/rapidjson/include\n",
            "\u001b[0mCMake Deprecation Warning at extern/pybind11/CMakeLists.txt:8 (cmake_minimum_required):\n",
            "  Compatibility with CMake < 3.10 will be removed from a future version of\n",
            "  CMake.\n",
            "\n",
            "  Update the VERSION argument <min> value.  Or, use the <min>...<max> syntax\n",
            "  to tell CMake that the project requires at least <min> but has been updated\n",
            "  to work with policies introduced by <max> or earlier.\n",
            "\n",
            "\u001b[0m\n",
            "\u001b[0mCMake Deprecation Warning at extern/pybind11/tools/pybind11Tools.cmake:8 (cmake_minimum_required):\n",
            "  Compatibility with CMake < 3.10 will be removed from a future version of\n",
            "  CMake.\n",
            "\n",
            "  Update the VERSION argument <min> value.  Or, use the <min>...<max> syntax\n",
            "  to tell CMake that the project requires at least <min> but has been updated\n",
            "  to work with policies introduced by <max> or earlier.\n",
            "Call Stack (most recent call first):\n",
            "  extern/pybind11/CMakeLists.txt:33 (include)\n",
            "\n",
            "\u001b[0m\n",
            "\u001b[33mCMake Warning (dev) at extern/pybind11/tools/FindPythonLibsNew.cmake:60 (find_package):\n",
            "  Policy CMP0148 is not set: The FindPythonInterp and FindPythonLibs modules\n",
            "  are removed.  Run \"cmake --help-policy CMP0148\" for policy details.  Use\n",
            "  the cmake_policy command to set the policy and suppress this warning.\n",
            "\n",
            "Call Stack (most recent call first):\n",
            "  extern/pybind11/tools/pybind11Tools.cmake:16 (find_package)\n",
            "  extern/pybind11/CMakeLists.txt:33 (include)\n",
            "This warning is for project developers.  Use -Wno-dev to suppress it.\n",
            "\u001b[0m\n",
            "-- Found PythonInterp: /usr/bin/python3.7 (found version \"3.7.17\")\n",
            "-- Found PythonLibs: /usr/lib/x86_64-linux-gnu/libpython3.7m.so\n",
            "-- pybind11 v2.3.0\n",
            "-- Performing Test CMAKE_HAVE_LIBC_PTHREAD\n",
            "-- Performing Test CMAKE_HAVE_LIBC_PTHREAD - Success\n",
            "-- Found Threads: TRUE\n",
            "-- Could NOT find GTest (missing: GTEST_LIBRARY GTEST_INCLUDE_DIR GTEST_MAIN_LIBRARY) \n",
            "-- Performing Test HAS_FLTO\n",
            "-- Performing Test HAS_FLTO - Success\n",
            "-- LTO enabled\n",
            "-- Configuring done (0.8s)\n",
            "-- Generating done (0.0s)\n",
            "-- Build files have been written to: /content/CityFlow/build\n",
            "[  7%] \u001b[32mBuilding CXX object src/CMakeFiles/cityflow_lib.dir/utility/utility.cpp.o\u001b[0m\n",
            "[ 15%] \u001b[32mBuilding CXX object src/CMakeFiles/cityflow_lib.dir/utility/barrier.cpp.o\u001b[0m\n",
            "[ 23%] \u001b[32mBuilding CXX object src/CMakeFiles/cityflow_lib.dir/engine/archive.cpp.o\u001b[0m\n",
            "[ 30%] \u001b[32mBuilding CXX object src/CMakeFiles/cityflow_lib.dir/engine/engine.cpp.o\u001b[0m\n",
            "[ 38%] \u001b[32mBuilding CXX object src/CMakeFiles/cityflow_lib.dir/flow/flow.cpp.o\u001b[0m\n",
            "[ 46%] \u001b[32mBuilding CXX object src/CMakeFiles/cityflow_lib.dir/roadnet/roadnet.cpp.o\u001b[0m\n",
            "[ 53%] \u001b[32mBuilding CXX object src/CMakeFiles/cityflow_lib.dir/roadnet/trafficlight.cpp.o\u001b[0m\n",
            "[ 61%] \u001b[32mBuilding CXX object src/CMakeFiles/cityflow_lib.dir/vehicle/router.cpp.o\u001b[0m\n",
            "[ 69%] \u001b[32mBuilding CXX object src/CMakeFiles/cityflow_lib.dir/vehicle/vehicle.cpp.o\u001b[0m\n",
            "[ 76%] \u001b[32mBuilding CXX object src/CMakeFiles/cityflow_lib.dir/vehicle/lanechange.cpp.o\u001b[0m\n",
            "[ 84%] \u001b[32m\u001b[1mLinking CXX static library libcityflow_lib.a\u001b[0m\n",
            "[ 84%] Built target cityflow_lib\n",
            "[ 92%] \u001b[32mBuilding CXX object CMakeFiles/cityflow.dir/src/cityflow.cpp.o\u001b[0m\n",
            "[100%] \u001b[32m\u001b[1mLinking CXX shared module cityflow.cpython-37m-x86_64-linux-gnu.so\u001b[0m\n",
            "lto-wrapper: warning: using serial compilation of 3 LTRANS jobs\n",
            "[100%] Built target cityflow\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cd /content/CityFlow/build"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "azoiUwArwW0S",
        "outputId": "fd5acb98-a808-4af6-c34b-da884c6e241b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/CityFlow/build\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install numpy"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LbhZr5eh26U2",
        "outputId": "968f84e2-d08a-4f17-e497-6b920b36d908"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (2.2.3)\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python3.7   c.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kh9pY4plMOIk",
        "outputId": "1ba485d3-21b5-417b-bc6e-92ec1a7d933d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  File \"c.py\", line 26\n",
            "    pip install numpy\n",
            "              ^\n",
            "SyntaxError: invalid syntax\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "print(sys.path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xqG9tXC8SHGS",
        "outputId": "441e7547-9cdc-45a2-a48b-f43514c457fb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['/content/CityFlow/build', '/content', '/env/python', '/usr/lib/python311.zip', '/usr/lib/python3.11', '/usr/lib/python3.11/lib-dynload', '', '/usr/local/lib/python3.11/dist-packages', '/usr/lib/python3/dist-packages', '/usr/local/lib/python3.11/dist-packages/IPython/extensions', '/root/.ipython']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "print(sys.version)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6cXCNPQdT-I6",
        "outputId": "4b775be0-6819-4c06-e705-6bfc3b89001e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3.11.11 (main, Dec  4 2024, 08:55:07) [GCC 11.4.0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!sudo update-alternatives --install /usr/bin/python3 python3 /usr/bin/python3.7 1"
      ],
      "metadata": {
        "id": "po2SC3HlVxkL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "factory.reset_runtime()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 144
        },
        "id": "g6gHwCIHT-Nm",
        "outputId": "e1eda8ed-c2ff-435f-850b-be1a08b57edc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'factory' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-69-f865f0f84c1b>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mfactory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset_runtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'factory' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "print(sys.version)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pb4EcigBSL00",
        "outputId": "e4eca945-0493-4c8c-bb7c-1354b1eb706e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3.11.11 (main, Dec  4 2024, 08:55:07) [GCC 11.4.0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ['PATH'] = '/usr/local/bin:' + os.environ.get('PATH', '')"
      ],
      "metadata": {
        "id": "OXQgvWjwTCCW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!ls /content/CityFlow/build"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tl9L1h4bMler",
        "outputId": "bf050ad9-12f1-49a1-b857-5cf114a6fd4c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "bdist.linux-x86_64\t\t\t  cmake_install.cmake\tsrc\n",
            "cityflow.cpython-37m-x86_64-linux-gnu.so  extern\t\ttemp.linux-x86_64-3.7\n",
            "CMakeCache.txt\t\t\t\t  lib.linux-x86_64-3.7\n",
            "CMakeFiles\t\t\t\t  Makefile\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cd /content/CityFlow"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8ueG50I8O182",
        "outputId": "fa06f9b8-5fe2-4bde-89d4-8f118394e09d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/CityFlow\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install ."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "atm-wdUvO4um",
        "outputId": "4e500d48-b04b-4824-9e26-2968a88c25de"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[31mERROR: Directory '.' is not installable. Neither 'setup.py' nor 'pyproject.toml' found.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python --version"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ann9ULwqXF3g",
        "outputId": "02258873-357a-4f6c-ee66-cbace29d2157"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Python 3.7.17\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import cityflow\n",
        "print(cityflow.__version__)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 340
        },
        "id": "2npv0zUkM8rV",
        "outputId": "6f00e340-ae9e-4c58-de89-5b17d75a126a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'cityflow'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-36-2f9bf1019f25>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mcityflow\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcityflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__version__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'cityflow'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Check Python version\n",
        "!python --version\n",
        "\n",
        "# Check installation location\n",
        "!pip show cityflow\n",
        "\n",
        "# Check Python path\n",
        "!python -c \"import sys; print(sys.path)\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2Ejw0VtbPRZX",
        "outputId": "7762adcc-9ce9-4209-bb72-0a256323df20"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Python 3.7.17\n",
            "Name: CityFlow\n",
            "Version: 0.1\n",
            "Summary: CityFlow: A Multi-Agent Reinforcement Learning Environment for Large Scale City Traffic Scenario\n",
            "Home-page: UNKNOWN\n",
            "Author: Huichu Zhang\n",
            "Author-email: zhc@apex.sjtu.edu.cn\n",
            "License: UNKNOWN\n",
            "Location: /usr/local/lib/python3.7/dist-packages\n",
            "Requires: \n",
            "Required-by: \n",
            "['', '/env/python', '/usr/lib/python37.zip', '/usr/lib/python3.7', '/usr/lib/python3.7/lib-dynload', '/usr/local/lib/python3.7/dist-packages', '/usr/lib/python3/dist-packages']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!chown $USER:$USER /content/CityFlow/build/cityflow.cpython-37m-x86_64-linux-gnu.so"
      ],
      "metadata": {
        "id": "3F6EXZyfQm9k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import cityflow\n",
        "\n",
        "eng = cityflow.Engine(config_path, thread_num=1)\n",
        "print(\"CityFlow installed successfully!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 376
        },
        "id": "rlCMzPb5PuoD",
        "outputId": "79563e1a-43f3-4617-8a4a-d538c658fc30"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'cityflow'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-54-eea80ed71315>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mcityflow\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0meng\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcityflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEngine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mthread_num\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"CityFlow installed successfully!\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'cityflow'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "sys.path.insert(0, '/content/CityFlow/build')"
      ],
      "metadata": {
        "id": "1UpT1nKlMbz_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "eng = cityflow.Engine(config_path, thread_num=1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 144
        },
        "id": "HI-oV5cNLEHW",
        "outputId": "c0b0ffcb-d3b0-418a-f6e5-41e835a0921c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'cityflow' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-82-251976859a1b>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0meng\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcityflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEngine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mthread_num\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'cityflow' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_hcxJRpN4ncA",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 340
        },
        "outputId": "cbf86803-784c-47cb-fd9f-1552947a396e"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'cityflow'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-17-48fec3df91ce>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mcityflow\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0meng\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCityFlow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEngine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/content/CityFlow/examples/config.json\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mthread_num\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'cityflow'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ],
      "source": [
        "import cityflow\n",
        "eng = CityFlow.Engine(\"/content/CityFlow/examples/config.json\", thread_num=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KREL7V4XQQII"
      },
      "outputs": [],
      "source": [
        "eng.set_tl_phase(\"intersection_1_1\",6 )\n",
        "eng.next_step()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FIdh8i5kC3RX"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "cell_1=np.zeros(8)\n",
        "\n",
        "for vehicle in eng.get_vehicles():\n",
        "\n",
        "\n",
        "   if \"TO\" not in eng.get_vehicle_info(vehicle).get('drivable'):\n",
        "       if \"road_0_1_0\" in eng.get_vehicle_info(vehicle).get('drivable') and float(eng.get_vehicle_info(vehicle).get('distance'))<60 :\n",
        "          print(float(eng.get_vehicle_info(vehicle).get('distance')))\n",
        "          cell_1[0]+=1\n",
        "          print(eng.get_vehicle_info(vehicle).get('drivable'))\n",
        "       if \"road_0_1_0\" in eng.get_vehicle_info(vehicle).get('drivable') and 60<float(eng.get_vehicle_info(vehicle).get('distance'))<130 :\n",
        "          print(float(eng.get_vehicle_info(vehicle).get('distance')))\n",
        "          cell_1[1]+=1\n",
        "          print(eng.get_vehicle_info(vehicle).get('drivable'))\n",
        "\n",
        "       if \"road_0_1_0\" in eng.get_vehicle_info(vehicle).get('drivable') and 130<float(eng.get_vehicle_info(vehicle).get('distance'))<160 :\n",
        "          print(float(eng.get_vehicle_info(vehicle).get('distance')))\n",
        "          cell_1[2]+=1\n",
        "          print(eng.get_vehicle_info(vehicle).get('drivable'))\n",
        "       if \"road_0_1_0\" in eng.get_vehicle_info(vehicle).get('drivable') and 160<float(eng.get_vehicle_info(vehicle).get('distance'))<200 :\n",
        "          print(float(eng.get_vehicle_info(vehicle).get('distance')))\n",
        "          cell_1[3]+=1\n",
        "          print(eng.get_vehicle_info(vehicle).get('drivable'))\n",
        "       if \"road_0_1_0\" in eng.get_vehicle_info(vehicle).get('drivable') and 200<float(eng.get_vehicle_info(vehicle).get('distance'))<235 :\n",
        "          print(float(eng.get_vehicle_info(vehicle).get('distance')))\n",
        "          cell_1[4]+=1\n",
        "          print(eng.get_vehicle_info(vehicle).get('drivable'))\n",
        "       if \"road_0_1_0\" in eng.get_vehicle_info(vehicle).get('drivable') and 235<float(eng.get_vehicle_info(vehicle).get('distance'))<255 :\n",
        "          print(float(eng.get_vehicle_info(vehicle).get('distance')))\n",
        "          cell_1[5]+=1\n",
        "          print(eng.get_vehicle_info(vehicle).get('drivable'))\n",
        "\n",
        "       if \"road_0_1_0\" in eng.get_vehicle_info(vehicle).get('drivable') and 255<float(eng.get_vehicle_info(vehicle).get('distance'))<265 :\n",
        "          print(float(eng.get_vehicle_info(vehicle).get('distance')))\n",
        "          cell_1[6]+=1\n",
        "          print(eng.get_vehicle_info(vehicle).get('drivable'))\n",
        "       if \"road_0_1_0\" in eng.get_vehicle_info(vehicle).get('drivable') and 265<float(eng.get_vehicle_info(vehicle).get('distance'))<269 :\n",
        "          print(float(eng.get_vehicle_info(vehicle).get('distance')))\n",
        "          cell_1[7]+=1\n",
        "          print(eng.get_vehicle_info(vehicle).get('drivable'))\n",
        "\n",
        "print(cell_1)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gRDWwM4I1rZ8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 305
        },
        "outputId": "3617b497-5ccf-45c3-fa0a-61050d3e18e7"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'eng' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-93-20fb24109c5f>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     18\u001b[0m    \u001b[0;32mreturn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcell_1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcell\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"road_0_1_0\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-93-20fb24109c5f>\u001b[0m in \u001b[0;36mcell\u001b[0;34m(road_id)\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mcell\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mroad_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m    \u001b[0mcell_1\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcell_nums\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m    \u001b[0;32mfor\u001b[0m \u001b[0mvehicle\u001b[0m \u001b[0;32min\u001b[0m \u001b[0meng\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_vehicles\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m         \u001b[0mdrivable\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0meng\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_vehicle_info\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvehicle\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'drivable'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0mdistance\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0meng\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_vehicle_info\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvehicle\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'distance'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'eng' is not defined"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "cell_nums=12\n",
        "\n",
        "cell_lengths=np.array([0,49,109,149,199,220,234,240,250,255,260,265,269])\n",
        "cell_lengths=np.array([0,49,109,149,199,220,234,240,250,255,260,265,269])\n",
        "\n",
        "def cell (road_id):\n",
        "   cell_1=np.zeros(cell_nums)\n",
        "   for vehicle in eng.get_vehicles():\n",
        "        drivable=eng.get_vehicle_info(vehicle).get('drivable')\n",
        "        distance=float(eng.get_vehicle_info(vehicle).get('distance'))\n",
        "        if \"TO\" not in drivable:\n",
        "             for cell_num in range(cell_nums):\n",
        "               if road_id in drivable and cell_lengths[cell_num]<distance<cell_lengths[cell_num+1] :\n",
        "                  cell_1[cell_num]+=1\n",
        "\n",
        "\n",
        "   return(cell_1)\n",
        "\n",
        "print(cell(\"road_0_1_0\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_KCIlPaj6Ac-",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 180
        },
        "outputId": "c32e0d17-8f5c-4a03-c7b7-230f2c114477"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'cell' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-92-ef7603719b6d>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     17\u001b[0m    \u001b[0;32mreturn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcell_1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcell\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"road_2_1_2\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'cell' is not defined"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "cell_nums=12\n",
        "\n",
        "cell_lengths=np.array([0,4,14,35,70,120,160,220,269])\n",
        "cell_lengths=np.array([0,4,10,14,20,25,35,48,70,120,160,220,269])\n",
        "def cell2 (road_id):\n",
        "   cell_1=np.zeros(cell_nums)\n",
        "   for vehicle in eng.get_vehicles():\n",
        "        drivable=eng.get_vehicle_info(vehicle).get('drivable')\n",
        "        distance=float(eng.get_vehicle_info(vehicle).get('distance'))\n",
        "        if \"TO\" not in drivable:\n",
        "             for cell_num in range(cell_nums):\n",
        "               if road_id in drivable and cell_lengths[cell_num]<distance<cell_lengths[cell_num+1] :\n",
        "                  cell_1[cell_nums-cell_num-1]+=1\n",
        "\n",
        "\n",
        "   return(cell_1)\n",
        "\n",
        "print(cell(\"road_2_1_2\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "07VOuSrI1e-Z"
      },
      "outputs": [],
      "source": [
        "road_celled_vehicle_nums=cell"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zLMbGG09HUXM"
      },
      "outputs": [],
      "source": [
        "road_0_1_0_celled_vehicle_nums=cell(\"road_0_1_0\")\n",
        "road_1_0_1_celled_vehicle_nums=cell(\"road_1_0_1\")\n",
        "road_2_1_2_celled_vehicle_nums=cell(\"road_2_1_2\")\n",
        "road_1_2_3_celled_vehicle_nums=cell(\"road_1_2_3\")\n",
        "road_1_1_0_celled_vehicle_nums=cell(\"road_1_1_0\")\n",
        "road_1_1_1_celled_vehicle_nums=cell(\"road_1_1_1\")\n",
        "road_1_1_3_celled_vehicle_nums=cell(\"road_1_1_3\")\n",
        "road_1_1_2_celled_vehicle_nums=cell(\"road_1_1_2\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hGUAiAlGO6Rp"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "observation=torch.tensor([road_0_1_0_celled_vehicle_nums,\n",
        "              road_1_0_1_celled_vehicle_nums,\n",
        "              road_2_1_2_celled_vehicle_nums,\n",
        "              road_1_2_3_celled_vehicle_nums,\n",
        "              road_1_1_2_celled_vehicle_nums,\n",
        "              road_1_1_3_celled_vehicle_nums,\n",
        "              road_1_1_0_celled_vehicle_nums,\n",
        "              road_1_1_1_celled_vehicle_nums],dtype=torch.float32)\n",
        "print(observation)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aR1Y3rbfGqnR"
      },
      "outputs": [],
      "source": [
        "sa = SelfAttention(d=8, d_q=4, d_k=4, d_v=4)\n",
        "cv = sa(sa)\n",
        "print(cv.shape)\n",
        "print(cv)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nzPssz0RlRVS"
      },
      "outputs": [],
      "source": [
        "print(eng.get_lane_vehicle_count())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rpSj9FyMjQkC"
      },
      "outputs": [],
      "source": [
        "import  gym\n",
        "from gym.spaces import Discrete\n",
        "from gym.spaces import Box\n",
        "import numpy as np\n",
        "import cv2\n",
        "import random\n",
        "import time\n",
        "from collections import deque\n",
        "from google.colab.patches import cv2_imshow\n",
        "from IPython.display import clear_output\n",
        "reward=[]\n",
        "class CityFlowEnv2(gym.Env):\n",
        "    def __init__(self):\n",
        "        super(CityFlowEnv2, self).__init__()\n",
        "        self.action_space = Discrete(8)\n",
        "        self.observation_space = Box(low=0.0,high=1.0,shape=(8,12), dtype=np.float32)\n",
        "\n",
        "    def step(self, action):\n",
        "        eng.set_tl_phase(\"intersection_1_1\",action )\n",
        "        eng.next_step()\n",
        "        road_0_1_0_celled_vehicle_nums=cell(\"road_0_1_0\")\n",
        "        road_1_0_1_celled_vehicle_nums=cell(\"road_1_0_1\")\n",
        "        road_2_1_2_celled_vehicle_nums=cell(\"road_2_1_2\")\n",
        "        road_1_2_3_celled_vehicle_nums=cell(\"road_1_2_3\")\n",
        "        road_1_1_0_celled_vehicle_nums=cell(\"road_1_1_0\")\n",
        "        road_1_1_1_celled_vehicle_nums=cell(\"road_1_1_1\")\n",
        "        road_1_1_3_celled_vehicle_nums=cell(\"road_1_1_3\")\n",
        "        road_1_1_2_celled_vehicle_nums=cell(\"road_1_1_2\")\n",
        "        observation=np.array([cell(\"road_0_1_0_0\"),\n",
        "              cell(\"road_1_0_1_0\"),\n",
        "              cell(\"road_2_1_2_0\"),\n",
        "              cell(\"road_1_2_3_0\"),\n",
        "              cell(\"road_1_1_0_0\"),\n",
        "              cell(\"road_1_1_1_0\"),\n",
        "              cell(\"road_1_1_3_0\"),\n",
        "              cell(\"road_1_1_2_0\"),\n",
        "              cell(\"road_0_1_0_1\"),\n",
        "              cell(\"road_1_0_1_1\"),\n",
        "              cell(\"road_2_1_2_1\"),\n",
        "              cell(\"road_1_2_3_1\"),\n",
        "              cell(\"road_1_1_0_1\"),\n",
        "              cell(\"road_1_1_1_1\"),\n",
        "              cell(\"road_1_1_3_1\"),\n",
        "              cell(\"road_1_1_2_1\"),\n",
        "              cell(\"road_0_1_0_2\"),\n",
        "              cell(\"road_1_0_1_2\"),\n",
        "              cell(\"road_2_1_2_2\"),\n",
        "              cell(\"road_1_2_3_2\"),\n",
        "              cell(\"road_1_1_0_2\"),\n",
        "              cell(\"road_1_1_1_2\"),\n",
        "              cell(\"road_1_1_3_2\"),\n",
        "              cell(\"road_1_1_2_2\"),\n",
        "            cell(\"road_0_1_0_0_3\"),\n",
        "              cell(\"road_1_0_1_3\"),\n",
        "              cell(\"road_2_1_2_3\"),\n",
        "              cell(\"road_1_2_3_3\"),\n",
        "              cell(\"road_1_1_0_3\"),\n",
        "              cell(\"road_1_1_1_3\"),\n",
        "              cell(\"road_1_1_3_3\"),\n",
        "              cell(\"road_1_1_2_3\"),\n",
        "           cell(\"road_0_1_0_4\"),\n",
        "              cell(\"road_1_0_1_4\"),\n",
        "              cell(\"road_2_1_2_4\"),\n",
        "              cell(\"road_1_2_3_4\"),\n",
        "              cell(\"road_1_1_0_4\"),\n",
        "              cell(\"road_1_1_1_4\"),\n",
        "              cell(\"road_1_1_3_4\"),\n",
        "              cell(\"road_1_1_2_4\"),\n",
        "         cell(\"road_0_1_0_5\"),\n",
        "              cell(\"road_1_0_1_5\"),\n",
        "              cell(\"road_2_1_2_5\"),\n",
        "              cell(\"road_1_2_3_5\"),\n",
        "              cell(\"road_1_1_0_5\"),\n",
        "              cell(\"road_1_1_1_5\"),\n",
        "              cell(\"road_1_1_3_5\"),\n",
        "              cell(\"road_1_1_2_5\"),\n",
        "          cell(\"road_0_1_0_6\"),\n",
        "              cell(\"road_1_0_1_6\"),\n",
        "              cell(\"road_2_1_2_6\"),\n",
        "              cell(\"road_1_2_3_6\"),\n",
        "              cell(\"road_1_1_0_6\"),\n",
        "              cell(\"road_1_1_1_6\"),\n",
        "              cell(\"road_1_1_3_6\"),\n",
        "              cell(\"road_1_1_2_6\"),\n",
        "          cell(\"road_0_1_0_7\"),\n",
        "              cell(\"road_1_0_1_7\"),\n",
        "              cell(\"road_2_1_2_7\"),\n",
        "              cell(\"road_1_2_3_7\"),\n",
        "              cell(\"road_1_1_0_7\"),\n",
        "              cell(\"road_1_1_1_7\"),\n",
        "              cell(\"road_1_1_3_7\"),\n",
        "              cell(\"road_1_1_2_7\")])\n",
        "        self.reward=1/sum(eng.get_lane_vehicle_count().values())\n",
        "        reward.append(self.reward)\n",
        "        avg_reward=sum(reward)/len(reward)\n",
        "\n",
        "\n",
        "        if eng.get_current_time()>1000:\n",
        "          reward.clear()\n",
        "          print(avg_reward)\n",
        "          self.done=True\n",
        "\n",
        "        info={}\n",
        "\n",
        "        return observation, self.reward, self.done, info\n",
        "\n",
        "    def reset(self ):\n",
        "        self.done=False\n",
        "        eng.reset()\n",
        "        eng.next_step()\n",
        "        observation=np.array([cell(\"road_0_1_0_0\"),\n",
        "              cell(\"road_1_0_1_0\"),\n",
        "              cell(\"road_2_1_2_0\"),\n",
        "              cell(\"road_1_2_3_0\"),\n",
        "              cell(\"road_1_1_0_0\"),\n",
        "              cell(\"road_1_1_1_0\"),\n",
        "              cell(\"road_1_1_3_0\"),\n",
        "              cell(\"road_1_1_2_0\"),\n",
        "              cell(\"road_0_1_0_1\"),\n",
        "              cell(\"road_1_0_1_1\"),\n",
        "              cell(\"road_2_1_2_1\"),\n",
        "              cell(\"road_1_2_3_1\"),\n",
        "              cell(\"road_1_1_0_1\"),\n",
        "              cell(\"road_1_1_1_1\"),\n",
        "              cell(\"road_1_1_3_1\"),\n",
        "              cell(\"road_1_1_2_1\"),\n",
        "              cell(\"road_0_1_0_2\"),\n",
        "              cell(\"road_1_0_1_2\"),\n",
        "              cell(\"road_2_1_2_2\"),\n",
        "              cell(\"road_1_2_3_2\"),\n",
        "              cell(\"road_1_1_0_2\"),\n",
        "              cell(\"road_1_1_1_2\"),\n",
        "              cell(\"road_1_1_3_2\"),\n",
        "              cell(\"road_1_1_2_2\"),\n",
        "            cell(\"road_0_1_0_0_3\"),\n",
        "              cell(\"road_1_0_1_3\"),\n",
        "              cell(\"road_2_1_2_3\"),\n",
        "              cell(\"road_1_2_3_3\"),\n",
        "              cell(\"road_1_1_0_3\"),\n",
        "              cell(\"road_1_1_1_3\"),\n",
        "              cell(\"road_1_1_3_3\"),\n",
        "              cell(\"road_1_1_2_3\"),\n",
        "           cell(\"road_0_1_0_4\"),\n",
        "              cell(\"road_1_0_1_4\"),\n",
        "              cell(\"road_2_1_2_4\"),\n",
        "              cell(\"road_1_2_3_4\"),\n",
        "              cell(\"road_1_1_0_4\"),\n",
        "              cell(\"road_1_1_1_4\"),\n",
        "              cell(\"road_1_1_3_4\"),\n",
        "              cell(\"road_1_1_2_4\"),\n",
        "         cell(\"road_0_1_0_5\"),\n",
        "              cell(\"road_1_0_1_5\"),\n",
        "              cell(\"road_2_1_2_5\"),\n",
        "              cell(\"road_1_2_3_5\"),\n",
        "              cell(\"road_1_1_0_5\"),\n",
        "              cell(\"road_1_1_1_5\"),\n",
        "              cell(\"road_1_1_3_5\"),\n",
        "              cell(\"road_1_1_2_5\"),\n",
        "          cell(\"road_0_1_0_6\"),\n",
        "              cell(\"road_1_0_1_6\"),\n",
        "              cell(\"road_2_1_2_6\"),\n",
        "              cell(\"road_1_2_3_6\"),\n",
        "              cell(\"road_1_1_0_6\"),\n",
        "              cell(\"road_1_1_1_6\"),\n",
        "              cell(\"road_1_1_3_6\"),\n",
        "              cell(\"road_1_1_2_6\"),\n",
        "          cell(\"road_0_1_0_7\"),\n",
        "              cell(\"road_1_0_1_7\"),\n",
        "              cell(\"road_2_1_2_7\"),\n",
        "              cell(\"road_1_2_3_7\"),\n",
        "              cell(\"road_1_1_0_7\"),\n",
        "              cell(\"road_1_1_1_7\"),\n",
        "              cell(\"road_1_1_3_7\"),\n",
        "              cell(\"road_1_1_2_7\")])\n",
        "\n",
        "        return observation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wQ0YOt83Wn_g"
      },
      "outputs": [],
      "source": [
        "import  gym\n",
        "from gym.spaces import Discrete\n",
        "from gym.spaces import Box\n",
        "import numpy as np\n",
        "import cv2\n",
        "import random\n",
        "import time\n",
        "from collections import deque\n",
        "from google.colab.patches import cv2_imshow\n",
        "from IPython.display import clear_output\n",
        "reward=[]\n",
        "class CityFlowEnv(gym.Env):\n",
        "    def __init__(self):\n",
        "        super(CityFlowEnv, self).__init__()\n",
        "        self.action_space = Discrete(8)\n",
        "        self.observation_space = Box(low=0.0,high=1.0,shape=(8,12), dtype=np.float32)\n",
        "\n",
        "    def step(self, action):\n",
        "        eng.set_tl_phase(\"intersection_1_1\",action )\n",
        "        eng.next_step()\n",
        "        road_0_1_0_celled_vehicle_nums=cell(\"road_0_1_0\")\n",
        "        road_1_0_1_celled_vehicle_nums=cell(\"road_1_0_1\")\n",
        "        road_2_1_2_celled_vehicle_nums=cell(\"road_2_1_2\")\n",
        "        road_1_2_3_celled_vehicle_nums=cell(\"road_1_2_3\")\n",
        "        road_1_1_0_celled_vehicle_nums=cell2(\"road_1_1_0\")\n",
        "        road_1_1_1_celled_vehicle_nums=cell2(\"road_1_1_1\")\n",
        "        road_1_1_3_celled_vehicle_nums=cell2(\"road_1_1_3\")\n",
        "        road_1_1_2_celled_vehicle_nums=cell2(\"road_1_1_2\")\n",
        "        observation=np.array([road_0_1_0_celled_vehicle_nums,\n",
        "              road_1_0_1_celled_vehicle_nums,\n",
        "              road_2_1_2_celled_vehicle_nums,\n",
        "              road_1_2_3_celled_vehicle_nums,\n",
        "              road_1_1_2_celled_vehicle_nums,\n",
        "              road_1_1_3_celled_vehicle_nums,\n",
        "              road_1_1_0_celled_vehicle_nums,\n",
        "              road_1_1_1_celled_vehicle_nums])\n",
        "        self.reward=1/sum(eng.get_lane_vehicle_count().values())\n",
        "        reward.append(self.reward)\n",
        "        avg_reward=sum(reward)/len(reward)\n",
        "\n",
        "\n",
        "        if eng.get_current_time()>1000:\n",
        "\n",
        "          reward.clear()\n",
        "          print(avg_reward)\n",
        "          self.done=True\n",
        "\n",
        "        info={}\n",
        "\n",
        "        return observation, self.reward, self.done, info\n",
        "\n",
        "    def reset(self ):\n",
        "        self.done=False\n",
        "        eng.reset()\n",
        "        eng.next_step()\n",
        "        road_0_1_0_celled_vehicle_nums=cell(\"road_0_1_0\")\n",
        "        road_1_0_1_celled_vehicle_nums=cell(\"road_1_0_1\")\n",
        "        road_2_1_2_celled_vehicle_nums=cell(\"road_2_1_2\")\n",
        "        road_1_2_3_celled_vehicle_nums=cell(\"road_1_2_3\")\n",
        "        road_1_1_0_celled_vehicle_nums=cell2(\"road_1_1_0\")\n",
        "        road_1_1_1_celled_vehicle_nums=cell2(\"road_1_1_1\")\n",
        "        road_1_1_3_celled_vehicle_nums=cell2(\"road_1_1_3\")\n",
        "        road_1_1_2_celled_vehicle_nums=cell2(\"road_1_1_2\")\n",
        "        observation=np.array([road_0_1_0_celled_vehicle_nums,\n",
        "              road_1_0_1_celled_vehicle_nums,\n",
        "              road_2_1_2_celled_vehicle_nums,\n",
        "              road_1_2_3_celled_vehicle_nums,\n",
        "              road_1_1_2_celled_vehicle_nums,\n",
        "              road_1_1_3_celled_vehicle_nums,\n",
        "              road_1_1_0_celled_vehicle_nums,\n",
        "              road_1_1_1_celled_vehicle_nums])\n",
        "\n",
        "        return observation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HS6L3QxVgaYg"
      },
      "outputs": [],
      "source": [
        "!pip install stable-baselines3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3AlOBKcUg-FR"
      },
      "outputs": [],
      "source": [
        "!pip install 'shimmy>=2.0'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "801ueiBxYNA1"
      },
      "outputs": [],
      "source": [
        "!pip install gymnasium\n",
        "!pip ins\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LcE8_xfigYVw",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 394
        },
        "outputId": "81d85037-89f2-4301-a83d-90d5a0ceb063"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'stable_baselines3'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-83-45126174cafe>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mstable_baselines3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mPPO\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'stable_baselines3'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ],
      "source": [
        "from stable_baselines3 import PPO\n",
        "import os\n",
        "\n",
        "import time\n",
        "\n",
        "\n",
        "\n",
        "# Define directories within the Colab's working directory\n",
        "models_dir = \"/content/models\"\n",
        "logdir = \"/content/logs\"\n",
        "\n",
        "# Ensure these directories exist\n",
        "os.makedirs(models_dir, exist_ok=True)\n",
        "os.makedirs(logdir, exist_ok=True)\n",
        "\n",
        "# Append timestamp for current session directories\n",
        "session_model_dir = f\"{models_dir}/{int(time.time())}\"\n",
        "session_log_dir = f\"{logdir}/{int(time.time())}\"\n",
        "\n",
        "# Make sure session directories are created\n",
        "os.makedirs(session_model_dir, exist_ok=True)\n",
        "os.makedirs(session_log_dir, exist_ok=True)\n",
        "\n",
        "print(f\"Model directory: {session_model_dir}\")\n",
        "print(f\"Log directory: {session_log_dir}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5iqaZcAMOW8O"
      },
      "outputs": [],
      "source": [
        "from stable_baselines3 import PPO\n",
        "import os\n",
        "\n",
        "import time\n",
        "\n",
        "\n",
        "\n",
        "models_dir = f\"models/{int(time.time())}/\"\n",
        "logdir = f\"logs/{int(time.time())}/\"\n",
        "\n",
        "if not os.path.exists(models_dir):\n",
        "\tos.makedirs(models_dir)\n",
        "\n",
        "if not os.path.exists(logdir):\n",
        "\tos.makedirs(logdir)\n",
        "\n",
        "env = CityFlowEnv()\n",
        "env.reset()\n",
        "\n",
        "model = PPO(CustomPolicy, env, verbose=1, tensorboard_log=session_log_dir)\n",
        "\n",
        "TIMESTEPS = 200000\n",
        "\n",
        "# Sum the number of elements in all parameters (weights) of the model\n",
        "total_params = sum(p.numel() for p in model.policy.parameters())\n",
        "\n",
        "print(f\"Total number of weights in the model: {total_params}\")\n",
        "\n",
        "model.learn(total_timesteps=TIMESTEPS, reset_num_timesteps=False, tb_log_name=f\"PPO\")\n",
        "model.save(session_model_dir)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lTQCgXZSVJmp"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6jJd48wIXCsZ"
      },
      "outputs": [],
      "source": [
        "model.policy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CfQkE2gm7sFd"
      },
      "outputs": [],
      "source": [
        "from keras.utils import plot_model\n",
        "plot_model(model, to_file='model.png', show_shapes=True, show_layer_names=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SHzan01xWHEH"
      },
      "outputs": [],
      "source": [
        "!pip install python-docx"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8ZY69Q3CrTCJ"
      },
      "outputs": [],
      "source": [
        "from binascii import a2b_base64\n",
        "import torch as th\n",
        "import torch.nn as nn\n",
        "import math\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.optim import SGD\n",
        "from docx import Document  # Corrected import\n",
        "\n",
        "# Create a document object\n",
        "doc = Document()\n",
        "# Create a document object\n",
        "doc = Document()\n",
        "import torch.nn.functional as F\n",
        "from stable_baselines3.common.policies import ActorCriticPolicy\n",
        "from stable_baselines3.common.torch_layers import BaseFeaturesExtractor\n",
        "from typing import Tuple\n",
        "# Custom Self-Attention Network\n",
        "class EncoderLayer(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(EncoderLayer, self).__init__()\n",
        "        self.norm1 = nn.LayerNorm(12)\n",
        "        self.norm2 = nn.LayerNorm(12)\n",
        "\n",
        "        self.dropout1 = nn.Dropout(0.1)\n",
        "        self.dropout2 = nn.Dropout(0.1)\n",
        "        self.self_attn = nn.MultiheadAttention(embed_dim=12, num_heads=1)\n",
        "        self.model=nn.Sequential(nn.Linear(12,32),nn.Tanh(),nn.Linear(32,32),nn.Tanh(),nn.Linear(32,12),nn.Tanh())\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    def forward(self, x: th.Tensor) -> th.Tensor:\n",
        "\n",
        "        attn_output, _ = self.self_attn(x, x, x)\n",
        "        x = x + attn_output\n",
        "        x = self.norm1(x)\n",
        "\n",
        "        ff_output= self.model(x)\n",
        "        x = x + ff_output\n",
        "        x = self.norm2(x)\n",
        "        return x\n",
        "\n",
        "class SelfAttention(nn.Module):\n",
        "    def __init__(self, d, d_q, d_k, d_v):\n",
        "        super(SelfAttention, self).__init__()\n",
        "        self.latent_dim_pi = 8\n",
        "        self.latent_dim_vf = 8\n",
        "        self.model1=nn.Sequential(nn.Linear(96,8),nn.Tanh())\n",
        "        self.model2=nn.Sequential(nn.Linear(96,8),nn.Tanh())\n",
        "        self.encoderlayer1=EncoderLayer()\n",
        "        self.encoderlayer2=EncoderLayer()\n",
        "        self.encoderlayer3=EncoderLayer()\n",
        "      #  self.encoderlayer4=EncoderLayer()\n",
        "     #   self.encoderlayer5=EncoderLayer()\n",
        "       # self.encoderlayer6=EncoderLayer()\n",
        "        self.encoderlayer7=EncoderLayer()\n",
        "        self.encoderlayer8=EncoderLayer()\n",
        "        self.encoderlayer9=EncoderLayer()\n",
        "       # self.encoderlayer10=EncoderLayer()\n",
        "      #  self.encoderlayer11=EncoderLayer()\n",
        "      #  self.encoderlayer12=EncoderLayer()\n",
        "    def forward(self, x: th.Tensor) -> Tuple[th.Tensor, th.Tensor]:\n",
        "\n",
        "\n",
        "      #context_vector2=self.policy_net2(context_vector2)\n",
        "      return self.forward_actor(x),self.forward_critic(x)\n",
        "\n",
        "\n",
        "    def forward_actor(self, x: th.Tensor) -> th.Tensor:\n",
        "        x=self.encoderlayer1(x)\n",
        "        x=self.encoderlayer2(x)\n",
        "        x=self.encoderlayer3(x)\n",
        "\n",
        "        x=self.model1(x.reshape(-1,96))\n",
        "        return x\n",
        "\n",
        "    def forward_critic(self, x: th.Tensor) -> th.Tensor:\n",
        "\n",
        "        x=self.encoderlayer7(x)\n",
        "        x=self.encoderlayer8(x)\n",
        "        x=self.encoderlayer9(x)\n",
        "        x=self.model2(x.reshape(-1,96))\n",
        "      #  doc.add_paragraph(f\"In-Projection Weights:\\n{self.encoderlayer7.self_attn.in_proj_weight.data}\")\n",
        "       # doc.add_paragraph(f\"Out-Projection Weights:\\n{self.encoderlayer7.self_attn.out_proj.weight.data}\")\n",
        "\n",
        "        # Save the document\n",
        "        doc.save('weights_log.docx')\n",
        "       # print(\"Weights have been saved to weights_log.docx\")\n",
        "        return x\n",
        "\n",
        "\n",
        "\n",
        "# Custom Policy incorporating the Self-Attention feature extractor\n",
        "class CustomPolicy(ActorCriticPolicy):\n",
        "    def __init__(self, observation_space, action_space, lr_schedule, *args, **kwargs):\n",
        "\n",
        "        use_sde = kwargs.pop('use_sde', False)\n",
        "        super(CustomPolicy, self).__init__(\n",
        "            observation_space,\n",
        "            action_space,\n",
        "            lr_schedule,\n",
        "\n",
        "\n",
        "            *args,\n",
        "            use_sde=use_sde,\n",
        "            **kwargs\n",
        "        )\n",
        "\n",
        "    def _build_mlp_extractor(self) -> None:\n",
        "\n",
        "        # Use the shared extracted features for both policy and value networks\n",
        "        self.features_extractor = nn.Identity()\n",
        "        self.mlp_extractor = SelfAttention(8,8,8,8)\n",
        "        self.pi_features_extractor= nn.Identity()\n",
        "        self.vf_features_extractor=nn.Identity()\n",
        "        self.action_net=nn.Identity()\n",
        "        self.value_net=nn.Identity()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "unuCOHTL1YDY"
      },
      "outputs": [],
      "source": [
        "from binascii import a2b_base64\n",
        "import torch as th\n",
        "import torch.nn as nn\n",
        "import math\n",
        "\n",
        "import torch.nn.functional as F\n",
        "from stable_baselines3.common.policies import ActorCriticPolicy\n",
        "from stable_baselines3.common.torch_layers import BaseFeaturesExtractor\n",
        "from typing import Tuple\n",
        "# Custom Self-Attention Network\n",
        "\n",
        "class SelfAttention(nn.Module):\n",
        "    def __init__(self, d, d_q, d_k, d_v):\n",
        "        super(SelfAttention, self).__init__()\n",
        "        self.latent_dim_pi = 16\n",
        "        self.latent_dim_vf = 16\n",
        "        # Define the encoder layer\n",
        "        self.encoder_layer1 = nn.TransformerEncoderLayer(\n",
        "        d_model=8,\n",
        "        nhead=1,\n",
        "        dim_feedforward=32,\n",
        "        dropout=0.1\n",
        "        )\n",
        "                # Multi-Head Attention\n",
        "        self.self_attn = nn.MultiheadAttention(embed_dim=8, num_heads=2)\n",
        "\n",
        "        # Feedforward Networks\n",
        "        self.linear1 = nn.Linear(8, 16)\n",
        "        self.linear2 = nn.Linear(16, 16)\n",
        "        self.linear3 = nn.Linear(16, 8)\n",
        "        self.linear4 = nn.Linear(8, 16)\n",
        "        self.linear5 = nn.Linear(16,16)\n",
        "        self.linear6 = nn.Linear(16,8)\n",
        "        self.model1=nn.Sequential(nn.Linear(16,16),nn.Tanh(),nn.Linear(16,16),nn.Tanh())\n",
        "        self.model2=nn.Sequential(nn.Linear(16,16),nn.Tanh(),nn.Linear(16,16),nn.Tanh())\n",
        "        # Layer Norms\n",
        "        self.norm1 = nn.LayerNorm(8)\n",
        "        self.norm2 = nn.LayerNorm(8)\n",
        "        self.norm3 = nn.LayerNorm(8)\n",
        "        self.norm4 = nn.LayerNorm(8)\n",
        "        # Dropout\n",
        "        self.dropout1 = nn.Dropout(0.1)\n",
        "        self.dropout2 = nn.Dropout(0.1)\n",
        "        self.dropout3 = nn.Dropout(0.1)\n",
        "        self.dropout4 = nn.Dropout(0.1)\n",
        "        self.encoder_layer2 = nn.TransformerEncoderLayer(\n",
        "        d_model=8,\n",
        "        nhead=1,\n",
        "        dim_feedforward=32,\n",
        "        dropout=0.1\n",
        "        )\n",
        "        self.TransformerEncoder1 = nn.TransformerEncoder(self.encoder_layer1, num_layers=6)\n",
        "        self.TransformerEncoder2 = nn.TransformerEncoder(self.encoder_layer2, num_layers=6)\n",
        "        # Policy network\n",
        "\n",
        "    def forward(self, x: th.Tensor) -> Tuple[th.Tensor, th.Tensor]:\n",
        "\n",
        "\n",
        "      #context_vector2=self.policy_net2(context_vector2)\n",
        "      return self.forward_actor(x),self.forward_critic(x)\n",
        "\n",
        "\n",
        "    def forward_actor(self, x: th.Tensor) -> th.Tensor:\n",
        "        x1=self.model1(x.reshape(-1,16))\n",
        "        attn_output, _ = self.self_attn(x, x, x)\n",
        "        x = x + self.dropout1(attn_output)\n",
        "        x = self.norm1(x)\n",
        "\n",
        "        ff_output= self.linear1(nn.Tanh(self.linear1(x)))\n",
        "        ff_output = self.linear2(ff_output)\n",
        "        ff_output = self.linear3(ff_output)\n",
        "        x = x + self.dropout2(ff_output)\n",
        "        x = self.norm2(x)\n",
        "        return x1\n",
        "\n",
        "    def forward_critic(self, x: th.Tensor) -> th.Tensor:\n",
        "        x2=self.model1(x.reshape(-1,16))\n",
        "        attn_output, _ = self.self_attn2(x, x, x)\n",
        "        x = x + self.dropout3(attn_output)\n",
        "        x = self.norm3(x)\n",
        "\n",
        "        ff_output= self.linear4(F.relu(self.linear1(x)))\n",
        "        ff_output = self.linear5(ff_output)\n",
        "        ff_output = self.linear6(ff_output)\n",
        "        x = x + self.dropout2(ff_output)\n",
        "        x = self.norm4(x)\n",
        "        return x2\n",
        "\n",
        "\n",
        "\n",
        "# Custom Policy incorporating the Self-Attention feature extractor\n",
        "class CustomPolicy(ActorCriticPolicy):\n",
        "    def __init__(self, observation_space, action_space, lr_schedule, *args, **kwargs):\n",
        "\n",
        "        use_sde = kwargs.pop('use_sde', False)\n",
        "        super(CustomPolicy, self).__init__(\n",
        "            observation_space,\n",
        "            action_space,\n",
        "            lr_schedule,\n",
        "\n",
        "\n",
        "            *args,\n",
        "            use_sde=use_sde,\n",
        "            **kwargs\n",
        "        )\n",
        "\n",
        "    def _build_mlp_extractor(self) -> None:\n",
        "\n",
        "        # Use the shared extracted features for both policy and value networks\n",
        "        self.features_extractor = nn.Identity()\n",
        "        self.mlp_extractor = SelfAttention(8,8,8,8)\n",
        "        self.pi_features_extractor= nn.Identity()\n",
        "        self.vf_features_extractor=nn.Identity()\n",
        "        self.action_net=nn.Identity()\n",
        "        self.value_net=nn.Identity()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HVoXq9RkFIDw"
      },
      "outputs": [],
      "source": [
        "from binascii import a2b_base64\n",
        "import torch as th\n",
        "import torch.nn as nn\n",
        "import math\n",
        "\n",
        "import torch.nn.functional as F\n",
        "from stable_baselines3.common.policies import ActorCriticPolicy\n",
        "from stable_baselines3.common.torch_layers import BaseFeaturesExtractor\n",
        "from typing import Tuple\n",
        "# Custom Self-Attention Network\n",
        "\n",
        "class SelfAttention(nn.Module):\n",
        "    def __init__(self, d, d_q, d_k, d_v):\n",
        "        super(SelfAttention, self).__init__()\n",
        "        self.latent_dim_pi = 64\n",
        "        self.latent_dim_vf = 64\n",
        "        # Define the encoder layer\n",
        "        self.encoder_layer1 = nn.TransformerEncoderLayer(\n",
        "        d_model=8,\n",
        "        nhead=1,\n",
        "        dim_feedforward=32,\n",
        "        dropout=0.1\n",
        "        )\n",
        "        self.encoder_layer2 = nn.TransformerEncoderLayer(\n",
        "        d_model=8,\n",
        "        nhead=1,\n",
        "        dim_feedforward=32,\n",
        "        dropout=0.1\n",
        "        )\n",
        "        self.TransformerEncoder1 = nn.TransformerEncoder(self.encoder_layer1, num_layers=6)\n",
        "        self.TransformerEncoder2 = nn.TransformerEncoder(self.encoder_layer2, num_layers=6)\n",
        "        # Policy network\n",
        "\n",
        "    def forward(self, x: th.Tensor) -> Tuple[th.Tensor, th.Tensor]:\n",
        "\n",
        "\n",
        "      #context_vector2=self.policy_net2(context_vector2)\n",
        "      return self.forward_actor(x),self.forward_critic(x)\n",
        "\n",
        "\n",
        "    def forward_actor(self, x: th.Tensor) -> th.Tensor:\n",
        "       return self.TransformerEncoder1(x.permute(0,1,2)).reshape(-1,64)\n",
        "\n",
        "    def forward_critic(self, x: th.Tensor) -> th.Tensor:\n",
        "\n",
        "       return self.TransformerEncoder2(x.permute(0,1,2)).reshape(-1,64)\n",
        "\n",
        "\n",
        "\n",
        "# Custom Policy incorporating the Self-Attention feature extractor\n",
        "class CustomPolicy(ActorCriticPolicy):\n",
        "    def __init__(self, observation_space, action_space, lr_schedule, *args, **kwargs):\n",
        "\n",
        "        use_sde = kwargs.pop('use_sde', False)\n",
        "        super(CustomPolicy, self).__init__(\n",
        "            observation_space,\n",
        "            action_space,\n",
        "            lr_schedule,\n",
        "\n",
        "\n",
        "            *args,\n",
        "            use_sde=use_sde,\n",
        "            **kwargs\n",
        "        )\n",
        "\n",
        "    def _build_mlp_extractor(self) -> None:\n",
        "\n",
        "        # Use the shared extracted features for both policy and value networks\n",
        "        self.features_extractor = nn.Identity()\n",
        "        self.mlp_extractor = SelfAttention(8,8,8,8)\n",
        "        self.pi_features_extractor= nn.Identity()\n",
        "        self.vf_features_extractor=nn.Identity()\n",
        "        self.action_net=nn.Identity()\n",
        "        self.value_net=nn.Identity()\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YX8nnWbtTW1s"
      },
      "outputs": [],
      "source": [
        "from binascii import a2b_base64\n",
        "import torch as th\n",
        "import torch.nn as nn\n",
        "import math\n",
        "\n",
        "import torch.nn.functional as F\n",
        "from stable_baselines3.common.policies import ActorCriticPolicy\n",
        "from stable_baselines3.common.torch_layers import BaseFeaturesExtractor\n",
        "from typing import Tuple\n",
        "# Custom Self-Attention Network\n",
        "\n",
        "class SelfAttention(nn.Module):\n",
        "    def __init__(self, d, d_q, d_k, d_v):\n",
        "        super(SelfAttention, self).__init__()\n",
        "        self.d = d\n",
        "        self.d_q = d_q\n",
        "        self.d_k = d_k\n",
        "        self.d_v = d_v\n",
        "        self.latent_dim_pi = 64\n",
        "        self.latent_dim_vf = 64\n",
        "        self.W_query = nn.Linear(8,8)\n",
        "        self.W_key = nn.Linear(8,8)\n",
        "        self.W_value = nn.Linear(8,8)\n",
        "        self.W_query1 = nn.Linear(8,8)\n",
        "        self.W_key1 = nn.Linear(8,8)\n",
        "        self.W_value1 = nn.Linear(8,8)\n",
        "        self.W_query2 = nn.Linear(8,8)\n",
        "        self.W_key2 = nn.Linear(8,8)\n",
        "        self.W_value2 = nn.Linear(8,8)\n",
        "        self.W_query3 = nn.Linear(8,8)\n",
        "        self.W_key3 = nn.Linear(8,8)\n",
        "        self.W_value3 = nn.Linear(8,8)\n",
        "        self.layer_norm1 = nn.LayerNorm(8)\n",
        "        self.layer_norm2 = nn.LayerNorm(8)\n",
        "        self.layer_norm3 = nn.LayerNorm(8)\n",
        "        self.layer_norm4 = nn.LayerNorm(8)\n",
        "        self.layer_norm5 = nn.LayerNorm(8)\n",
        "        self.layer_norm6 = nn.LayerNorm(8)\n",
        "        self.layer_norm7 = nn.LayerNorm(8)\n",
        "        self.layer_norm8 = nn.LayerNorm(8)\n",
        "        # Define the encoder layer\n",
        "        self.encoder_layer = nn.TransformerEncoderLayer(\n",
        "        d_model=8,\n",
        "        nhead=8,\n",
        "        dim_feedforward=8,\n",
        "        dropout=0.1\n",
        "        )\n",
        "        self.TransformerEncoder = nn.TransformerEncoder(self.encoder_layer, num_layers=2)\n",
        "        self.Multihead_attention= nn.MultiheadAttention(8, 1)\n",
        "        # Policy network\n",
        "        self.policy_net1 = nn.Sequential(\n",
        "            nn.Linear(64, 64), nn.Tanh(),\n",
        "        )\n",
        "        self.policy_net2 = nn.Sequential(\n",
        "            nn.Linear(64, 64), nn.Tanh(),\n",
        "        )\n",
        "        self.policy_net3 = nn.Sequential(\n",
        "            nn.Linear(64, 64), nn.ReLU(),\n",
        "            nn.Linear(64, 64), nn.ReLU(),\n",
        "        )\n",
        "        self.policy_net4 = nn.Sequential(\n",
        "            nn.Linear(64, 64), nn.ReLU(),\n",
        "            nn.Linear(64, 64), nn.ReLU(),\n",
        "\n",
        "        )\n",
        "        self.mask=[]\n",
        "        self.feedl1=nn.Linear(8,16)\n",
        "        self.feedl2=nn.Linear(8,16)\n",
        "        self.feedl3=nn.Linear(8,16)\n",
        "        self.feedl4=nn.Linear(8,16)\n",
        "        self.feedl5=nn.Linear(8,16)\n",
        "        self.feedl6=nn.Linear(8,16)\n",
        "        self.feedl7=nn.Linear(8,16)\n",
        "        self.feedl8=nn.Linear(8,16)\n",
        "        self.feedm1=nn.Linear(16,16)\n",
        "        self.feedm2=nn.Linear(16,16)\n",
        "        self.feedm3=nn.Linear(16,16)\n",
        "        self.feedm4=nn.Linear(16,16)\n",
        "        self.feedm5=nn.Linear(16,16)\n",
        "        self.feedm6=nn.Linear(16,16)\n",
        "        self.feedm7=nn.Linear(16,16)\n",
        "        self.feedm8=nn.Linear(16,16)\n",
        "        self.feedh1=nn.Linear(16,8)\n",
        "        self.feedh2=nn.Linear(16,8)\n",
        "        self.feedh3=nn.Linear(16,8)\n",
        "        self.feedh4=nn.Linear(16,8)\n",
        "        self.feedh5=nn.Linear(16,8)\n",
        "        self.feedh6=nn.Linear(16,8)\n",
        "        self.feedh7=nn.Linear(16,8)\n",
        "        self.feedh8=nn.Linear(16,8)\n",
        "        self.Feedl1=nn.Linear(8,16)\n",
        "        self.Feedl2=nn.Linear(8,16)\n",
        "        self.Feedl3=nn.Linear(8,16)\n",
        "        self.Feedl4=nn.Linear(8,16)\n",
        "        self.Feedl5=nn.Linear(8,16)\n",
        "        self.Feedl6=nn.Linear(8,16)\n",
        "        self.Feedl7=nn.Linear(8,16)\n",
        "        self.Feedl8=nn.Linear(8,16)\n",
        "        self.Feedm1=nn.Linear(16,16)\n",
        "        self.Feedm2=nn.Linear(16,16)\n",
        "        self.Feedm3=nn.Linear(16,16)\n",
        "        self.Feedm4=nn.Linear(16,16)\n",
        "        self.Feedm5=nn.Linear(16,16)\n",
        "        self.Feedm6=nn.Linear(16,16)\n",
        "        self.Feedm7=nn.Linear(16,16)\n",
        "        self.Feedm8=nn.Linear(16,16)\n",
        "        self.Feedh1=nn.Linear(16,8)\n",
        "        self.Feedh2=nn.Linear(16,8)\n",
        "        self.Feedh3=nn.Linear(16,8)\n",
        "        self.Feedh4=nn.Linear(16,8)\n",
        "        self.Feedh5=nn.Linear(16,8)\n",
        "        self.Feedh6=nn.Linear(16,8)\n",
        "        self.Feedh7=nn.Linear(16,8)\n",
        "        self.Feedh8=nn.Linear(16,8)\n",
        "        self.feedl_1=nn.Linear(8,16)\n",
        "        self.feedl_2=nn.Linear(8,16)\n",
        "        self.feedl_3=nn.Linear(8,16)\n",
        "        self.feedl_4=nn.Linear(8,16)\n",
        "        self.feedl_5=nn.Linear(8,16)\n",
        "        self.feedl_6=nn.Linear(8,16)\n",
        "        self.feedl_7=nn.Linear(8,16)\n",
        "        self.feedl_8=nn.Linear(8,16)\n",
        "        self.feedm_1=nn.Linear(16,16)\n",
        "        self.feedm_2=nn.Linear(16,16)\n",
        "        self.feedm_3=nn.Linear(16,16)\n",
        "        self.feedm_4=nn.Linear(16,16)\n",
        "        self.feedm_5=nn.Linear(16,16)\n",
        "        self.feedm_6=nn.Linear(16,16)\n",
        "        self.feedm_7=nn.Linear(16,16)\n",
        "        self.feedm_8=nn.Linear(16,16)\n",
        "        self.feedh_1=nn.Linear(16,8)\n",
        "        self.feedh_2=nn.Linear(16,8)\n",
        "        self.feedh_3=nn.Linear(16,8)\n",
        "        self.feedh_4=nn.Linear(16,8)\n",
        "        self.feedh_5=nn.Linear(16,8)\n",
        "        self.feedh_6=nn.Linear(16,8)\n",
        "        self.feedh_7=nn.Linear(16,8)\n",
        "        self.feedh_8=nn.Linear(16,8)\n",
        "        self.Feedl_1=nn.Linear(8,16)\n",
        "        self.Feedl_2=nn.Linear(8,16)\n",
        "        self.Feedl_3=nn.Linear(8,16)\n",
        "        self.Feedl_4=nn.Linear(8,16)\n",
        "        self.Feedl_5=nn.Linear(8,16)\n",
        "        self.Feedl_6=nn.Linear(8,16)\n",
        "        self.Feedl_7=nn.Linear(8,16)\n",
        "        self.Feedl_8=nn.Linear(8,16)\n",
        "        self.Feedm_1=nn.Linear(16,16)\n",
        "        self.Feedm_2=nn.Linear(16,16)\n",
        "        self.Feedm_3=nn.Linear(16,16)\n",
        "        self.Feedm_4=nn.Linear(16,16)\n",
        "        self.Feedm_5=nn.Linear(16,16)\n",
        "        self.Feedm_6=nn.Linear(16,16)\n",
        "        self.Feedm_7=nn.Linear(16,16)\n",
        "        self.Feedm_8=nn.Linear(16,16)\n",
        "        self.Feedh_1=nn.Linear(16,8)\n",
        "        self.Feedh_2=nn.Linear(16,8)\n",
        "        self.Feedh_3=nn.Linear(16,8)\n",
        "        self.Feedh_4=nn.Linear(16,8)\n",
        "        self.Feedh_5=nn.Linear(16,8)\n",
        "        self.Feedh_6=nn.Linear(16,8)\n",
        "        self.Feedh_7=nn.Linear(16,8)\n",
        "        self.Feedh_8=nn.Linear(16,8)\n",
        "    def forward(self, x: th.Tensor) -> Tuple[th.Tensor, th.Tensor]:\n",
        "\n",
        "\n",
        "      #context_vector2=self.policy_net2(context_vector2)\n",
        "      return self.TransformerEncoder(x.permute(1,0,2)).reshape(-1,64),self.TransformerEncoder(x.permute(1,0,2)).reshape(-1,64)\n",
        "\n",
        "\n",
        "\n",
        "    def forward_actor(self, x: th.Tensor) -> th.Tensor:\n",
        "\n",
        "\n",
        "      x=x.reshape(-1, 8)\n",
        "      Q = self.W_query(x)\n",
        "\n",
        "      K = self.W_key(x)\n",
        "      V = self.W_value(x)\n",
        "\n",
        "      attention_scores = Q @ K.T / math.sqrt(self.d_k)\n",
        "      attention_weights = F.softmax(attention_scores, dim=-1)\n",
        "      context_vector = attention_weights @ V\n",
        "\n",
        "      #context_vector=self.layer_norm(x+context_vector)\n",
        "      #context_vector=self.policy_net1(context_vector)\n",
        "      context_vector=self.layer_norm1(x+context_vector)\n",
        "      context_vector1=context_vector.reshape(-1,8,8)\n",
        "      A1=self.feedl1(context_vector1.transpose(1,0)[0])\n",
        "      a1= nn.Tanh()(A1)\n",
        "      a1=self.feedm1(a1)\n",
        "      a1=nn.Tanh()(a1)\n",
        "      a1=self.feedh1(a1)\n",
        "      a1=nn.Tanh()(a1)\n",
        "\n",
        "      A2=self.feedl2(context_vector1.transpose(1,0)[1])\n",
        "      a2=nn.Tanh()(A2)\n",
        "      a2=self.feedm2(a2)\n",
        "      a2=nn.Tanh()(a2)\n",
        "      a2=self.feedh2(a2)\n",
        "      a2=nn.Tanh()(a2)\n",
        "\n",
        "      A3=self.feedl3(context_vector1.transpose(1,0)[2])\n",
        "      a3=nn.Tanh()(A3)\n",
        "      a3=self.feedm3(a3)\n",
        "      a3=nn.Tanh()(a3)\n",
        "      a3=self.feedh3(a3)\n",
        "      a3=nn.Tanh()(a3)\n",
        "\n",
        "      A4=self.feedl4(context_vector1.transpose(1,0)[3])\n",
        "      a4=nn.Tanh()(A4)\n",
        "      a4=self.feedm4(a4)\n",
        "      a4=nn.Tanh()(a4)\n",
        "      a4=self.feedh4(a4)\n",
        "      a4=nn.Tanh()(a4)\n",
        "\n",
        "      A5=self.feedl5(context_vector1.transpose(1,0)[4])\n",
        "      a5=nn.Tanh()(A5)\n",
        "      a5=self.feedm5(a5)\n",
        "      a5=nn.Tanh()(a5)\n",
        "      a5=self.feedh5(a5)\n",
        "      a5=nn.Tanh()(a5)\n",
        "\n",
        "      A6=self.feedl6(context_vector1.transpose(1,0)[5])\n",
        "      a6=nn.Tanh()(A6)\n",
        "      a6=self.feedm6(a6)\n",
        "      a6=nn.Tanh()(a6)\n",
        "      a6=self.feedh6(a6)\n",
        "      a6=nn.Tanh()(a6)\n",
        "\n",
        "      A7=self.feedl7(context_vector1.transpose(1,0)[6])\n",
        "      a7=nn.Tanh()(A7)\n",
        "      a7=self.feedm7(a7)\n",
        "      a7=nn.Tanh()(a7)\n",
        "      a7=self.feedh7(a7)\n",
        "      a7=nn.Tanh()(a7)\n",
        "\n",
        "      A8=self.feedl8(context_vector1.transpose(1,0)[7])\n",
        "      a8=nn.Tanh()(A8)\n",
        "      a8=self.feedm8(a8)\n",
        "      a8=nn.Tanh()(a8)\n",
        "      a8=self.feedh7(a8)\n",
        "      a8=nn.Tanh()(a8)\n",
        "\n",
        "      context_vector2 = th.stack([a1, a2, a3, a4, a5, a6, a7, a8]).transpose(0, 1)\n",
        "\n",
        "\n",
        "      #context_vector2=context_vector2.reshape(-1,64)\n",
        "\n",
        "\n",
        "      context_vector2=context_vector2.reshape(-1, 8)\n",
        "      context_vector1=context_vector1.reshape(-1, 8)\n",
        "      x2=self.layer_norm2(context_vector2+context_vector1)\n",
        "\n",
        "\n",
        "\n",
        "      Q = self.W_query1(x2)\n",
        "      K = self.W_key1(x2)\n",
        "      V = self.W_value1(x2)\n",
        "      attention_scores = Q @ K.T / math.sqrt(self.d_k)\n",
        "      attention_weights = F.softmax(attention_scores, dim=-1)\n",
        "      context_vector2 = attention_weights @ V\n",
        "      context_vector2=self.layer_norm3(x2+context_vector2)\n",
        "      context_vector3=context_vector2.reshape(-1,8,8)\n",
        "      B1=self.feedl_1(context_vector3.transpose(1,0)[0])\n",
        "      b1=nn.Tanh()(B1)\n",
        "      b1=self.feedm_1(b1)\n",
        "      b1=nn.Tanh()(b1)\n",
        "      b1=self.feedh_1(b1)\n",
        "      b1=nn.Tanh()(b1)\n",
        "\n",
        "      B2=self.feedl_2(context_vector3.transpose(1,0)[1])\n",
        "      b2=nn.Tanh()(B2)\n",
        "      b2=self.feedm_2(b2)\n",
        "      b2=nn.Tanh()(b2)\n",
        "      b2=self.feedh_2(b2)\n",
        "      b2=nn.Tanh()(b2)\n",
        "\n",
        "      B3=self.feedl_3(context_vector3.transpose(1,0)[2])\n",
        "      b3=nn.Tanh()(B3)\n",
        "      b3=self.feedm_3(b3)\n",
        "      b3=nn.Tanh()(b3)\n",
        "      b3=self.feedh_3(b3)\n",
        "      b3=nn.Tanh()(b3)\n",
        "\n",
        "\n",
        "      B4=self.feedl_4(context_vector3.transpose(1,0)[3])\n",
        "      b4=nn.Tanh()(B4)\n",
        "      b4=self.feedm_4(b4)\n",
        "      b4=nn.Tanh()(b4)\n",
        "      b4=self.feedh_4(b4)\n",
        "      b4=nn.Tanh()(b4)\n",
        "\n",
        "      B5=self.feedl_5(context_vector3.transpose(1,0)[4])\n",
        "      b5=nn.Tanh()(B5)\n",
        "      b5=self.feedm_5(b5)\n",
        "      b5=nn.Tanh()(b5)\n",
        "      b5=self.feedh_5(b5)\n",
        "      b5=nn.Tanh()(b5)\n",
        "\n",
        "      B6=self.feedl_6(context_vector3.transpose(1,0)[5])\n",
        "      b6=nn.Tanh()(B6)\n",
        "      b6=self.feedm_6(b6)\n",
        "      b6=nn.Tanh()(b6)\n",
        "      b6=self.feedh_6(b6)\n",
        "      b6=nn.Tanh()(b6)\n",
        "\n",
        "      B7=self.feedl_7(context_vector3.transpose(1,0)[6])\n",
        "      b7=nn.Tanh()(B7)\n",
        "      b7=self.feedm_7(b7)\n",
        "      b7=nn.Tanh()(b7)\n",
        "      b7=self.feedh_7(b7)\n",
        "      b7=nn.Tanh()(b7)\n",
        "\n",
        "      B8=self.feedl_8(context_vector3.transpose(1,0)[7])\n",
        "      b8=nn.Tanh()(B8)\n",
        "      b8=self.feedm_8(b8)\n",
        "      b8=nn.Tanh()(b8)\n",
        "      b8=self.Feedh_8(b8)\n",
        "      b8=nn.Tanh()(b8)\n",
        "\n",
        "      context_vector3 = th.stack([b1, b2, b3, b4, b5, b6, b7, b8]).transpose(0, 1)\n",
        "      context_vector3=context_vector3.reshape(-1, 8)\n",
        "      context_vector3=self.layer_norm4(context_vector3+context_vector2)\n",
        "\n",
        "      return context_vector3.reshape(-1,64)\n",
        "\n",
        "    def forward_critic(self, x: th.Tensor) -> th.Tensor:\n",
        "\n",
        "\n",
        "      x=x.reshape(-1, 8)\n",
        "      Q = self.W_query(x)\n",
        "\n",
        "      K = self.W_key(x)\n",
        "      V = self.W_value(x)\n",
        "\n",
        "      attention_scores = Q @ K.T / math.sqrt(self.d_k)\n",
        "      attention_weights = F.softmax(attention_scores, dim=-1)\n",
        "      context_vector = attention_weights @ V\n",
        "\n",
        "      #context_vector=self.layer_norm(x+context_vector)\n",
        "      #context_vector=self.policy_net1(context_vector)\n",
        "      context_vector=self.layer_norm1(x+context_vector)\n",
        "      context_vector1=context_vector.reshape(-1,8,8)\n",
        "      A1=self.feedl1(context_vector1.transpose(1,0)[0])\n",
        "      a1= nn.Tanh()(A1)\n",
        "      a1=self.feedm1(a1)\n",
        "      a1=nn.Tanh()(a1)\n",
        "      a1=self.feedh1(a1)\n",
        "      a1=nn.Tanh()(a1)\n",
        "\n",
        "      A2=self.feedl2(context_vector1.transpose(1,0)[1])\n",
        "      a2=nn.Tanh()(A2)\n",
        "      a2=self.feedm2(a2)\n",
        "      a2=nn.Tanh()(a2)\n",
        "      a2=self.feedh2(a2)\n",
        "      a2=nn.Tanh()(a2)\n",
        "\n",
        "      A3=self.feedl3(context_vector1.transpose(1,0)[2])\n",
        "      a3=nn.Tanh()(A3)\n",
        "      a3=self.feedm3(a3)\n",
        "      a3=nn.Tanh()(a3)\n",
        "      a3=self.feedh3(a3)\n",
        "      a3=nn.Tanh()(a3)\n",
        "\n",
        "      A4=self.feedl4(context_vector1.transpose(1,0)[3])\n",
        "      a4=nn.Tanh()(A4)\n",
        "      a4=self.feedm4(a4)\n",
        "      a4=nn.Tanh()(a4)\n",
        "      a4=self.feedh4(a4)\n",
        "      a4=nn.Tanh()(a4)\n",
        "\n",
        "      A5=self.feedl5(context_vector1.transpose(1,0)[4])\n",
        "      a5=nn.Tanh()(A5)\n",
        "      a5=self.feedm5(a5)\n",
        "      a5=nn.Tanh()(a5)\n",
        "      a5=self.feedh5(a5)\n",
        "      a5=nn.Tanh()(a5)\n",
        "\n",
        "      A6=self.feedl6(context_vector1.transpose(1,0)[5])\n",
        "      a6=nn.Tanh()(A6)\n",
        "      a6=self.feedm6(a6)\n",
        "      a6=nn.Tanh()(a6)\n",
        "      a6=self.feedh6(a6)\n",
        "      a6=nn.Tanh()(a6)\n",
        "\n",
        "      A7=self.feedl7(context_vector1.transpose(1,0)[6])\n",
        "      a7=nn.Tanh()(A7)\n",
        "      a7=self.feedm7(a7)\n",
        "      a7=nn.Tanh()(a7)\n",
        "      a7=self.feedh7(a7)\n",
        "      a7=nn.Tanh()(a7)\n",
        "\n",
        "      A8=self.feedl8(context_vector1.transpose(1,0)[7])\n",
        "      a8=nn.Tanh()(A8)\n",
        "      a8=self.feedm8(a8)\n",
        "      a8=nn.Tanh()(a8)\n",
        "      a8=self.feedh7(a8)\n",
        "      a8=nn.Tanh()(a8)\n",
        "\n",
        "      context_vector2 = th.stack([a1, a2, a3, a4, a5, a6, a7, a8]).transpose(0, 1)\n",
        "\n",
        "\n",
        "      #context_vector2=context_vector2.reshape(-1,64)\n",
        "\n",
        "\n",
        "      context_vector2=context_vector2.reshape(-1, 8)\n",
        "      context_vector1=context_vector1.reshape(-1, 8)\n",
        "      x2=self.layer_norm2(context_vector2+context_vector1)\n",
        "\n",
        "\n",
        "\n",
        "      Q = self.W_query1(x2)\n",
        "      K = self.W_key1(x2)\n",
        "      V = self.W_value1(x2)\n",
        "      attention_scores = Q @ K.T / math.sqrt(self.d_k)\n",
        "      attention_weights = F.softmax(attention_scores, dim=-1)\n",
        "      context_vector2 = attention_weights @ V\n",
        "      context_vector2=self.layer_norm3(x2+context_vector2)\n",
        "      context_vector3=context_vector2.reshape(-1,8,8)\n",
        "      B1=self.feedl_1(context_vector3.transpose(1,0)[0])\n",
        "      b1=nn.Tanh()(B1)\n",
        "      b1=self.feedm_1(b1)\n",
        "      b1=nn.Tanh()(b1)\n",
        "      b1=self.feedh_1(b1)\n",
        "      b1=nn.Tanh()(b1)\n",
        "\n",
        "      B2=self.feedl_2(context_vector3.transpose(1,0)[1])\n",
        "      b2=nn.Tanh()(B2)\n",
        "      b2=self.feedm_2(b2)\n",
        "      b2=nn.Tanh()(b2)\n",
        "      b2=self.feedh_2(b2)\n",
        "      b2=nn.Tanh()(b2)\n",
        "\n",
        "      B3=self.feedl_3(context_vector3.transpose(1,0)[2])\n",
        "      b3=nn.Tanh()(B3)\n",
        "      b3=self.feedm_3(b3)\n",
        "      b3=nn.Tanh()(b3)\n",
        "      b3=self.feedh_3(b3)\n",
        "      b3=nn.Tanh()(b3)\n",
        "\n",
        "\n",
        "      B4=self.feedl_4(context_vector3.transpose(1,0)[3])\n",
        "      b4=nn.Tanh()(B4)\n",
        "      b4=self.feedm_4(b4)\n",
        "      b4=nn.Tanh()(b4)\n",
        "      b4=self.feedh_4(b4)\n",
        "      b4=nn.Tanh()(b4)\n",
        "\n",
        "      B5=self.feedl_5(context_vector3.transpose(1,0)[4])\n",
        "      b5=nn.Tanh()(B5)\n",
        "      b5=self.feedm_5(b5)\n",
        "      b5=nn.Tanh()(b5)\n",
        "      b5=self.feedh_5(b5)\n",
        "      b5=nn.Tanh()(b5)\n",
        "\n",
        "      B6=self.feedl_6(context_vector3.transpose(1,0)[5])\n",
        "      b6=nn.Tanh()(B6)\n",
        "      b6=self.feedm_6(b6)\n",
        "      b6=nn.Tanh()(b6)\n",
        "      b6=self.feedh_6(b6)\n",
        "      b6=nn.Tanh()(b6)\n",
        "\n",
        "      B7=self.feedl_7(context_vector3.transpose(1,0)[6])\n",
        "      b7=nn.Tanh()(B7)\n",
        "      b7=self.feedm_7(b7)\n",
        "      b7=nn.Tanh()(b7)\n",
        "      b7=self.feedh_7(b7)\n",
        "      b7=nn.Tanh()(b7)\n",
        "\n",
        "      B8=self.feedl_8(context_vector3.transpose(1,0)[7])\n",
        "      b8=nn.Tanh()(B8)\n",
        "      b8=self.feedm_8(b8)\n",
        "      b8=nn.Tanh()(b8)\n",
        "      b8=self.feedh_8(b8)\n",
        "      b8=nn.Tanh()(b8)\n",
        "\n",
        "      context_vector3 = th.stack([b1, b2, b3, b4, b5, b6, b7, b8]).transpose(0, 1)\n",
        "      context_vector3=context_vector3.reshape(-1, 8)\n",
        "      context_vector3=self.layer_norm4(context_vector3+context_vector2)\n",
        "\n",
        "      return context_vector3.reshape(-1,64)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Stacked Self-Attention Network\n",
        "class StackedSelfAttention(nn.Module):\n",
        "    def __init__(self, d, d_q, d_k, d_v):\n",
        "        super(StackedSelfAttention, self).__init__()\n",
        "        self.attention1 = SelfAttention(d, d_q, d_k, d_v)\n",
        "        self.attention2 = SelfAttention(d, d_q, d_k, d_v)\n",
        "        self.attention3 = SelfAttention(d, d_q, d_k, d_v)\n",
        "    def forward(self, x):\n",
        "        output1 = self.attention1(x)\n",
        "        output2 = self.attention2(output1)\n",
        "        output3 = self.attention3(output2)\n",
        "        return output3\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Custom Policy incorporating the Self-Attention feature extractor\n",
        "class CustomPolicy(ActorCriticPolicy):\n",
        "    def __init__(self, observation_space, action_space, lr_schedule, *args, **kwargs):\n",
        "\n",
        "        use_sde = kwargs.pop('use_sde', False)\n",
        "        super(CustomPolicy, self).__init__(\n",
        "            observation_space,\n",
        "            action_space,\n",
        "            lr_schedule,\n",
        "\n",
        "\n",
        "            *args,\n",
        "            use_sde=use_sde,\n",
        "            **kwargs\n",
        "        )\n",
        "\n",
        "    def _build_mlp_extractor(self) -> None:\n",
        "\n",
        "        # Use the shared extracted features for both policy and value networks\n",
        "        self.features_extractor = nn.Identity()\n",
        "        self.mlp_extractor = SelfAttention(8,8,8,8)\n",
        "        self.pi_features_extractor= nn.Identity()\n",
        "        self.vf_features_extractor=nn.Identity()\n",
        "        self.action_net=nn.Identity()\n",
        "        self.value_net=nn.Identity()\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4ZvXpeOakjir"
      },
      "outputs": [],
      "source": [
        "x=th.tensor([[[1,1,1,1],\n",
        "                [2,2,2,2],\n",
        "                [3,3,3,3],\n",
        "                [4,4,4,4]],\n",
        "             [[1,1,1,1],\n",
        "                [2,2,2,2],\n",
        "                [3,3,3,3],\n",
        "                [4,4,4,4]]])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iKx5yydAmO8o"
      },
      "outputs": [],
      "source": [
        "y=x.transpose(1,0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dIfCkR38zQqW"
      },
      "outputs": [],
      "source": [
        "print(y)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "46iDRvg-JFmW"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fQKbSF5zHWJ_"
      },
      "outputs": [],
      "source": [
        "logdir="
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LMrY3TOBkdSS"
      },
      "outputs": [],
      "source": [
        "%load_ext tensorboard\n",
        "%tensorboard --logdir {session_log_dir}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e3cJdL-AX3vA"
      },
      "outputs": [],
      "source": [
        "SnekEnv().observation_space"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tal_s6My3wnA"
      },
      "outputs": [],
      "source": [
        "!pip install flask\n",
        "!pip install pyngrok"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g5kvavPM3-SQ"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import threading\n",
        "\n",
        "from flask import Flask, send_from_directory\n",
        "from pyngrok import ngrok, conf\n",
        "\n",
        "conf.get_default().auth_token = \"2mvyff2uSdlUcxalE2IUUuUp75y_6XsoFStUb6cKWWea7Wwma\"\n",
        "\n",
        "FRONTEND_DIR = \"/content/CityFlow/frontend\"\n",
        "app = Flask(__name__, static_folder=FRONTEND_DIR, template_folder=FRONTEND_DIR)\n",
        "\n",
        "# Open a ngrok tunnel to the HTTP server\n",
        "public_url = ngrok.connect(5000).public_url\n",
        "print(\" * ngrok tunnel \\\"{}\\\" -> \\\"http://127.0.0.1:{}/\\\"\".format(public_url, 5000))\n",
        "\n",
        "# Update any base URLs to use the public ngrok URL\n",
        "app.config[\"BASE_URL\"] = public_url\n",
        "\n",
        "# ... Update inbound traffic via APIs to use the public-facing ngrok URL\n",
        "\n",
        "\n",
        "# Route for the main page\n",
        "@app.route(\"/\")\n",
        "def index():\n",
        "    return send_from_directory(FRONTEND_DIR, \"index.html\")\n",
        "\n",
        "# Route for static files (CSS, JS, images, etc.)\n",
        "@app.route(\"/<path:path>\")\n",
        "def serve_static(path):\n",
        "    return send_from_directory(FRONTEND_DIR, path)\n",
        "\n",
        "\n",
        "def run_app():\n",
        "    app.run(host='0.0.0.0', port=5000)\n",
        "\n",
        "# Start the Flask server in a new thread\n",
        "threading.Thread(target=run_app).start()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J8X0lV_HCUYc"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "\n",
        "# Define the input tensor of shape (32, 8)\n",
        "input_tensor = torch.tensor([\n",
        "    [3., 0., 0., 0., 0., 0., 0., 0.],\n",
        "    [3., 0., 0., 0., 0., 0., 0., 0.],\n",
        "    [3., 0., 0., 0., 0., 0., 0., 0.],\n",
        "    [3., 0., 0., 0., 0., 0., 0., 0.],\n",
        "    [0., 0., 0., 0., 0., 0., 0., 0.],\n",
        "    [0., 0., 0., 0., 0., 0., 0., 0.],\n",
        "    [0., 0., 0., 0., 0., 0., 0., 0.],\n",
        "    [0., 0., 0., 0., 0., 0., 0., 0.],\n",
        "    [3., 0., 0., 0., 0., 0., 0., 0.],\n",
        "    [3., 0., 0., 0., 0., 0., 0., 0.],\n",
        "    [3., 0., 0., 0., 0., 0., 0., 0.],\n",
        "    [3., 0., 0., 0., 0., 0., 0., 0.],\n",
        "    [0., 0., 0., 0., 0., 0., 0., 0.],\n",
        "    [0., 0., 0., 0., 0., 0., 0., 0.],\n",
        "    [0., 0., 0., 0., 0., 0., 0., 0.],\n",
        "    [0., 0., 0., 0., 0., 0., 0., 0.],\n",
        "    [3., 0., 0., 0., 0., 0., 0., 0.],\n",
        "    [3., 0., 0., 0., 0., 0., 0., 0.],\n",
        "    [3., 0., 0., 0., 0., 0., 0., 0.],\n",
        "    [3., 0., 0., 0., 0., 0., 0., 0.],\n",
        "    [0., 0., 0., 0., 0., 0., 0., 0.],\n",
        "    [0., 0., 0., 0., 0., 0., 0., 0.],\n",
        "    [0., 0., 0., 0., 0., 0., 0., 0.],\n",
        "    [0., 0., 0., 0., 0., 0., 0., 0.],\n",
        "    [3., 0., 0., 0., 0., 0., 0., 0.],\n",
        "    [3., 0., 0., 0., 0., 0., 0., 0.],\n",
        "    [3., 0., 0., 0., 0., 0., 0., 0.],\n",
        "    [3., 0., 0., 0., 0., 0., 0., 0.],\n",
        "    [0., 0., 0., 0., 0., 0., 0., 0.],\n",
        "    [0., 0., 0., 0., 0., 0., 0., 0.],\n",
        "    [0., 0., 0., 0., 0., 0., 0., 0.],\n",
        "    [0., 0., 0., 0., 0., 0., 0., 0.]\n",
        "])\n",
        "\n",
        "# Reshape the tensor from shape (32, 8) to shape (3, 8, 8)\n",
        "# Here we slice and concatenate rows to form each 8x8 layer\n",
        "layer1 = input_tensor[0:8].flatten()\n",
        "layer2 = input_tensor[8:16].flatten()\n",
        "layer3 = input_tensor[16:24].flatten()\n",
        "\n",
        "# Combine layers into the final 3D tensor\n",
        "output_tensor = torch.stack([layer1, layer2, layer3])\n",
        "\n",
        "# Print the reshaped tensor\n",
        "print(output_tensor)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O2dewhR6IgXI"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "\n",
        "# Create your 2D tensor with shape (32, 8)\n",
        "input_tensor = torch.tensor([\n",
        "    [3., 0., 0., 0., 0., 0., 0., 0.],\n",
        "    [3., 0., 0., 0., 0., 0., 0., 0.],\n",
        "    [3., 0., 0., 0., 0., 0., 0., 0.],\n",
        "    [3., 0., 0., 0., 0., 0., 0., 0.],\n",
        "    [0., 0., 0., 0., 0., 0., 0., 0.],\n",
        "    [0., 0., 0., 0., 0., 0., 0., 0.],\n",
        "    [0., 0., 0., 0., 0., 0., 0., 0.],\n",
        "    [0., 0., 0., 0., 0., 0., 0., 0.],\n",
        "    [3., 0., 0., 0., 0., 0., 0., 0.],\n",
        "    [3., 0., 0., 0., 0., 0., 0., 0.],\n",
        "    [3., 0., 0., 0., 0., 0., 0., 0.],\n",
        "    [3., 0., 0., 0., 0., 0., 0., 0.],\n",
        "    [0., 0., 0., 0., 0., 0., 0., 0.],\n",
        "    [0., 0., 0., 0., 0., 0., 0., 0.],\n",
        "    [0., 0., 0., 0., 0., 0., 0., 0.],\n",
        "    [0., 0., 0., 0., 0., 0., 0., 0.],\n",
        "    [3., 0., 0., 0., 0., 0., 0., 0.],\n",
        "    [3., 0., 0., 0., 0., 0., 0., 0.],\n",
        "    [3., 0., 0., 0., 0., 0., 0., 0.],\n",
        "    [3., 0., 0., 0., 0., 0., 0., 0.],\n",
        "    [0., 0., 0., 0., 0., 0., 0., 0.],\n",
        "    [0., 0., 0., 0., 0., 0., 0., 0.],\n",
        "    [0., 0., 0., 0., 0., 0., 0., 0.],\n",
        "    [0., 0., 0., 0., 0., 0., 0., 0.],\n",
        "    [3., 0., 0., 0., 0., 0., 0., 0.],\n",
        "    [3., 0., 0., 0., 0., 0., 0., 0.],\n",
        "    [3., 0., 0., 0., 0., 0., 0., 0.],\n",
        "    [3., 0., 0., 0., 0., 0., 0., 0.],\n",
        "    [0., 0., 0., 0., 0., 0., 0., 0.],\n",
        "    [0., 0., 0., 0., 0., 0., 0., 0.],\n",
        "    [0., 0., 0., 0., 0., 0., 0., 0.],\n",
        "    [0., 0., 0., 0., 0., 0., 0., 0.]\n",
        "])\n",
        "\n",
        "# Reshape the tensor into shape (4, 8, 8)\n",
        "reshaped_tensor = input_tensor.view(4, 8, 8)\n",
        "\n",
        "# Flatten each (8, 8) block and stack them\n",
        "flattened_blocks = reshaped_tensor.view(4, -1)\n",
        "print(len(input_tensor)/4)\n",
        "# Print the new tensor\n",
        "print(flattened_blocks)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kKCQDBpl6mv-"
      },
      "outputs": [],
      "source": [
        "x=th.tensor([[[1,2,3,4],\n",
        "               [5,6,7,8],\n",
        "                [9,10,11,12],\n",
        "                 [13,14,15,16]],\n",
        "                 [[17,18,19,20],\n",
        "               [21,22,23,24],\n",
        "                [25,26,27,28],\n",
        "                 [29,30,31,32]]])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CvfPKlhz7ONX"
      },
      "outputs": [],
      "source": [
        "y=x.transpose(1,0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1yQVwenJ9nEV"
      },
      "outputs": [],
      "source": [
        "z=y.transpose(0,1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Mt8eNJuI8eDP"
      },
      "outputs": [],
      "source": [
        "print(z)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1S47IXFDqkDa"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "# Define the Multihead Attention layer\n",
        "embed_dim = 64   # Embedding dimension\n",
        "num_heads = 1    # Number of attention heads\n",
        "batch_size = 2   # Batch size\n",
        "seq_length = 10  # Sequence length\n",
        "\n",
        "# Initialize the MultiHeadAttention layer\n",
        "multihead_attention = nn.MultiheadAttention(embed_dim, num_heads)\n",
        "\n",
        "# Sample input tensor: (seq_length, batch_size, embed_dim)\n",
        "query = torch.rand(seq_length, batch_size, embed_dim)\n",
        "key = query  # Self-attention, so key = query\n",
        "value = query  # Self-attention, so value = query\n",
        "\n",
        "# Forward pass through the multihead attention\n",
        "output, attention_weights = multihead_attention(query, key, value)\n",
        "\n",
        "print(\"Output shape:\", output.shape)  # Should be (seq_length, batch_size, embed_dim)\n",
        "print(\"Attention Weights shape:\", attention_weights.shape)"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "AjdpxT8tOslu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "MtgTw2-bOtjE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "wEasf6H6Cru9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "2x3toyKjCtIk"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPijTWtl2xmyLoHVqxuJ5D6",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}